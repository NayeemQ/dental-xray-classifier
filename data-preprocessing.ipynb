{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train split...\n",
      "  Found 576 images in class 'Cavity'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Cavity: 100%|██████████| 576/576 [00:08<00:00, 64.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 5242 images in class 'Fillings'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Fillings: 100%|██████████| 5242/5242 [01:18<00:00, 66.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 428 images in class 'Impacted Tooth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Impacted Tooth: 100%|██████████| 428/428 [00:05<00:00, 74.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 1784 images in class 'Implant'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Implant: 100%|██████████| 1784/1784 [00:27<00:00, 65.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 17106 images in class 'Normal'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Normal: 100%|██████████| 17106/17106 [03:56<00:00, 72.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train split: 25136 images processed\n",
      "Processing valid split...\n",
      "  Found 43 images in class 'Cavity'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Cavity: 100%|██████████| 43/43 [00:00<00:00, 58.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 540 images in class 'Fillings'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Fillings: 100%|██████████| 540/540 [00:07<00:00, 68.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 38 images in class 'Impacted Tooth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Impacted Tooth: 100%|██████████| 38/38 [00:00<00:00, 78.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 159 images in class 'Implant'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Implant: 100%|██████████| 159/159 [00:02<00:00, 73.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 2032 images in class 'Normal'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Normal: 100%|██████████| 2032/2032 [00:27<00:00, 73.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  valid split: 2812 images processed\n",
      "Processing test split...\n",
      "  Found 22 images in class 'Cavity'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Cavity: 100%|██████████| 22/22 [00:00<00:00, 72.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 315 images in class 'Fillings'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Fillings: 100%|██████████| 315/315 [00:04<00:00, 71.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 32 images in class 'Impacted Tooth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Impacted Tooth: 100%|██████████| 32/32 [00:00<00:00, 69.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 104 images in class 'Implant'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Implant: 100%|██████████| 104/104 [00:01<00:00, 78.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 1176 images in class 'Normal'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Normal: 100%|██████████| 1176/1176 [00:18<00:00, 63.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test split: 1649 images processed\n",
      "\n",
      "Dataset Statistics:\n",
      "--------------------------------------------------\n",
      "Train set:\n",
      "  Total images: 25136\n",
      "  Shape: (25136, 64, 64, 1)\n",
      "  Range: [0.0000, 1.0000]\n",
      "  Mean: 0.4022\n",
      "  Std: 0.3742\n",
      "  Class distribution:\n",
      "    Cavity: 576 (2.29%)\n",
      "    Fillings: 5242 (20.85%)\n",
      "    Impacted Tooth: 428 (1.70%)\n",
      "    Implant: 1784 (7.10%)\n",
      "    Normal: 17106 (68.05%)\n",
      "------------------------------\n",
      "Valid set:\n",
      "  Total images: 2812\n",
      "  Shape: (2812, 64, 64, 1)\n",
      "  Range: [0.0000, 1.0000]\n",
      "  Mean: 0.3980\n",
      "  Std: 0.3759\n",
      "  Class distribution:\n",
      "    Cavity: 43 (1.53%)\n",
      "    Fillings: 540 (19.20%)\n",
      "    Impacted Tooth: 38 (1.35%)\n",
      "    Implant: 159 (5.65%)\n",
      "    Normal: 2032 (72.26%)\n",
      "------------------------------\n",
      "Test set:\n",
      "  Total images: 1649\n",
      "  Shape: (1649, 64, 64, 1)\n",
      "  Range: [0.0000, 1.0000]\n",
      "  Mean: 0.4168\n",
      "  Std: 0.3786\n",
      "  Class distribution:\n",
      "    Cavity: 22 (1.33%)\n",
      "    Fillings: 315 (19.10%)\n",
      "    Impacted Tooth: 32 (1.94%)\n",
      "    Implant: 104 (6.31%)\n",
      "    Normal: 1176 (71.32%)\n",
      "------------------------------\n",
      "Processed data saved to processed_data\n",
      "Preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Define the dataset structure\n",
    "data_dir = \"Dental_Radiography\"  # Root directory of your dataset\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "classes = [\"Cavity\", \"Fillings\", \"Impacted Tooth\", \"Implant\", \"Normal\"]\n",
    "\n",
    "def load_and_preprocess_images(data_dir, splits, classes):\n",
    "    \"\"\"\n",
    "    Load all images from the specified directory structure,\n",
    "    preprocess them, and convert to numpy arrays with labels.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Contains X and y arrays for each split\n",
    "    \"\"\"\n",
    "    # Dictionary to store processed data\n",
    "    dataset = {}\n",
    "    \n",
    "    for split in splits:\n",
    "        print(f\"Processing {split} split...\")\n",
    "        \n",
    "        # Lists to store images and labels\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        # Process each class\n",
    "        for class_idx, class_name in enumerate(classes):\n",
    "            class_dir = os.path.join(data_dir, split, class_name)\n",
    "            \n",
    "            # Check if directory exists\n",
    "            if not os.path.exists(class_dir):\n",
    "                print(f\"Warning: Directory {class_dir} not found. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            # Get list of image files\n",
    "            image_files = [f for f in os.listdir(class_dir) if f.lower().endswith('.png')]\n",
    "            \n",
    "            print(f\"  Found {len(image_files)} images in class '{class_name}'\")\n",
    "            \n",
    "            # Process each image\n",
    "            for img_file in tqdm(image_files, desc=f\"Processing {class_name}\"):\n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                \n",
    "                try:\n",
    "                    # Open image as grayscale\n",
    "                    img = Image.open(img_path).convert('L')\n",
    "                    \n",
    "                    # Convert to numpy array and normalize to [0, 1]\n",
    "                    img_array = np.array(img) / 255.0\n",
    "                    \n",
    "                    # Ensure the image is 64x64\n",
    "                    if img_array.shape != (64, 64):\n",
    "                        img = img.resize((64, 64), Image.LANCZOS)\n",
    "                        img_array = np.array(img) / 255.0\n",
    "                    \n",
    "                    # Add image and label to lists\n",
    "                    images.append(img_array)\n",
    "                    labels.append(class_idx)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_path}: {e}\")\n",
    "        \n",
    "        # Convert lists to numpy arrays\n",
    "        X = np.array(images)\n",
    "        y = np.array(labels)\n",
    "        \n",
    "        # Reshape to include channel dimension: (n_samples, height, width, channels)\n",
    "        X = X.reshape(X.shape[0], 64, 64, 1)\n",
    "        \n",
    "        # Store in dataset dictionary\n",
    "        dataset[split] = {\n",
    "            'X': X,\n",
    "            'y': y\n",
    "        }\n",
    "        \n",
    "        print(f\"  {split} split: {X.shape[0]} images processed\")\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "def visualize_samples(dataset, classes, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualize random samples from each class in the training set\n",
    "    \"\"\"\n",
    "    X_train = dataset['train']['X']\n",
    "    y_train = dataset['train']['y']\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        # Get indices for this class\n",
    "        indices = np.where(y_train == class_idx)[0]\n",
    "        \n",
    "        # Select random samples\n",
    "        if len(indices) >= num_samples:\n",
    "            selected_indices = np.random.choice(indices, num_samples, replace=False)\n",
    "            \n",
    "            # Plot images\n",
    "            for i, idx in enumerate(selected_indices):\n",
    "                plt.subplot(len(classes), num_samples, class_idx * num_samples + i + 1)\n",
    "                plt.imshow(X_train[idx].reshape(64, 64), cmap='gray')\n",
    "                plt.axis('off')\n",
    "                \n",
    "                if i == 0:\n",
    "                    plt.title(class_name)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_dental_xrays.png')\n",
    "    plt.close()\n",
    "\n",
    "def save_processed_data(dataset, output_dir=\"processed_data\"):\n",
    "    \"\"\"\n",
    "    Save the processed dataset as numpy files\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for split in dataset.keys():\n",
    "        # Save X and y arrays\n",
    "        np.save(os.path.join(output_dir, f\"X_{split}.npy\"), dataset[split]['X'])\n",
    "        np.save(os.path.join(output_dir, f\"y_{split}.npy\"), dataset[split]['y'])\n",
    "    \n",
    "    # Save class names\n",
    "    with open(os.path.join(output_dir, 'class_names.pkl'), 'wb') as f:\n",
    "        pickle.dump(classes, f)\n",
    "    \n",
    "    print(f\"Processed data saved to {output_dir}\")\n",
    "\n",
    "def print_dataset_stats(dataset):\n",
    "    \"\"\"\n",
    "    Print statistics about the dataset\n",
    "    \"\"\"\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for split in dataset.keys():\n",
    "        X = dataset[split]['X']\n",
    "        y = dataset[split]['y']\n",
    "        \n",
    "        print(f\"{split.capitalize()} set:\")\n",
    "        print(f\"  Total images: {X.shape[0]}\")\n",
    "        print(f\"  Shape: {X.shape}\")\n",
    "        print(f\"  Range: [{X.min():.4f}, {X.max():.4f}]\")\n",
    "        print(f\"  Mean: {X.mean():.4f}\")\n",
    "        print(f\"  Std: {X.std():.4f}\")\n",
    "        \n",
    "        # Class distribution\n",
    "        print(\"  Class distribution:\")\n",
    "        for class_idx, class_name in enumerate(classes):\n",
    "            count = np.sum(y == class_idx)\n",
    "            percentage = (count / len(y)) * 100\n",
    "            print(f\"    {class_name}: {count} ({percentage:.2f}%)\")\n",
    "        \n",
    "        print(\"-\" * 30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process the dataset\n",
    "    dataset = load_and_preprocess_images(data_dir, splits, classes)\n",
    "    \n",
    "    # Print statistics\n",
    "    print_dataset_stats(dataset)\n",
    "    \n",
    "    # Visualize samples\n",
    "    visualize_samples(dataset, classes)\n",
    "    \n",
    "    # Save processed data\n",
    "    save_processed_data(dataset)\n",
    "    \n",
    "    print(\"Preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=np.load('./processed_data/X_test.npy')\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.load('./processed_data/y_test.npy')\n",
    "y[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "henv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
