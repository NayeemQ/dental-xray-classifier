{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2SyqMkpkWWg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "import random\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLRE0d55koZe"
      },
      "outputs": [],
      "source": [
        "# GPU Configuration\n",
        "def configure_gpu():\n",
        "    \"\"\"Configure TensorFlow to use GPU resources efficiently\"\"\"\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            # Memory growth prevents TensorFlow from allocating all GPU memory at once\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "            print(f\"Found {len(gpus)} GPU(s). GPU acceleration enabled.\")\n",
        "\n",
        "            # Optionally, you can limit GPU memory allocation\n",
        "            # tf.config.experimental.set_virtual_device_configuration(\n",
        "            #     gpus[0],\n",
        "            #     [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]\n",
        "            # )\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            print(f\"GPU configuration error: {e}\")\n",
        "    else:\n",
        "        print(\"No GPU found. Running on CPU.\")\n",
        "\n",
        "    return len(gpus) > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVtYwvshkwfE"
      },
      "outputs": [],
      "source": [
        "def load_data(data_dir):\n",
        "    \"\"\"\n",
        "    Load the preprocessed data\n",
        "    \"\"\"\n",
        "    # Load arrays\n",
        "    X_train = np.load(os.path.join(data_dir, \"X_train_augmented.npy\"))\n",
        "    y_train = np.load(os.path.join(data_dir, \"y_train_augmented.npy\"))\n",
        "    X_valid = np.load(os.path.join(data_dir, \"X_valid.npy\"))\n",
        "    y_valid = np.load(os.path.join(data_dir, \"y_valid.npy\"))\n",
        "    X_test = np.load(os.path.join(data_dir, \"X_test.npy\"))\n",
        "    y_test = np.load(os.path.join(data_dir, \"y_test.npy\"))\n",
        "\n",
        "    # Load class names\n",
        "    #data_dir_classes='/content/drive/MyDrive/Colab Notebooks/processed_data'\n",
        "    with open(os.path.join(data_dir, 'class_names.pkl'), 'rb') as f:\n",
        "        class_names = pickle.load(f)\n",
        "        print(class_names)\n",
        "\n",
        "    return X_train, y_train, X_valid, y_valid, X_test, y_test, class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utb4FJculBVh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import Layer\n",
        "from tensorflow.keras.layers import (Conv2D, BatchNormalization, MaxPooling2D,\n",
        "                                    Dropout, Dense, Flatten, Lambda,\n",
        "                                    Activation, GlobalAveragePooling2D,\n",
        "                                    Multiply, Add, Reshape)\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "import tensorflow as tf\n",
        "\n",
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    \"\"\"Custom F1 score metric for sparse categorical data\"\"\"\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.precision = tf.keras.metrics.Precision()\n",
        "        self.recall = tf.keras.metrics.Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "        self.precision.update_state(y_true, y_pred)\n",
        "        self.recall.update_state(y_true, y_pred)\n",
        "\n",
        "    def result(self):\n",
        "        p = self.precision.result()\n",
        "        r = self.recall.result()\n",
        "        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.precision.reset_state()\n",
        "        self.recall.reset_state()\n",
        "\n",
        "\n",
        "class SelfAttention(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, h, w, c = input_shape\n",
        "        self.query_conv = Conv2D(c//8, (1,1))\n",
        "        self.key_conv = Conv2D(c//8, (1,1))\n",
        "        self.value_conv = Conv2D(c, (1,1))\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        query = self.query_conv(x)\n",
        "        key = self.key_conv(x)\n",
        "        value = self.value_conv(x)\n",
        "\n",
        "        # Reshape for attention calculation\n",
        "        query_flat = tf.reshape(query, [-1, tf.shape(query)[1]*tf.shape(query)[2], tf.shape(query)[3]])\n",
        "        key_flat = tf.reshape(key, [-1, tf.shape(key)[1]*tf.shape(key)[2], tf.shape(key)[3]])\n",
        "        value_flat = tf.reshape(value, [-1, tf.shape(value)[1]*tf.shape(value)[2], tf.shape(value)[3]])\n",
        "\n",
        "        # Attention scores\n",
        "        attention = tf.matmul(query_flat, key_flat, transpose_b=True)\n",
        "        attention = tf.nn.softmax(attention)\n",
        "\n",
        "        # Weighted sum\n",
        "        out = tf.matmul(attention, value_flat)\n",
        "\n",
        "        # Reshape back to original\n",
        "        out = tf.reshape(out, [-1, tf.shape(x)[1], tf.shape(x)[2], tf.shape(value)[3]])\n",
        "        return out + x  # Residual connection\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "class SEBlock(Layer):\n",
        "    def __init__(self, ratio=16, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.ratio = ratio\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, _, _, c = input_shape\n",
        "        self.se_dense_reduce = Dense(c//self.ratio, activation='relu')\n",
        "        self.se_dense_expand = Dense(c, activation='sigmoid')\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        se = GlobalAveragePooling2D()(x)\n",
        "        se = self.se_dense_reduce(se)\n",
        "        se = self.se_dense_expand(se)\n",
        "        return Multiply()([x, Reshape((1,1,-1))(se)])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "def create_enhanced_model(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Final enhanced CNN model with proper custom layers\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input normalization\n",
        "    model.add(Lambda(lambda x: tf.image.per_image_standardization(x),\n",
        "              input_shape=input_shape))\n",
        "\n",
        "    # --- First Convolutional Block ---\n",
        "    model.add(Conv2D(32, (3,3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(lambda x: x * tf.sigmoid(x)))  # Swish\n",
        "\n",
        "    # --- Second Convolutional Block ---\n",
        "    model.add(Conv2D(64, (3,3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(lambda x: x * tf.sigmoid(x)))\n",
        "\n",
        "    # Add self-attention\n",
        "    model.add(SelfAttention())\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # --- Third Convolutional Block ---\n",
        "    model.add(Conv2D(128, (1,5), padding='same'))\n",
        "    model.add(Conv2D(128, (5,1), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation(lambda x: x * tf.sigmoid(x)))\n",
        "\n",
        "    # Add SE block\n",
        "    model.add(SEBlock(ratio=16))\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # --- Feature Processing ---\n",
        "    model.add(Conv2D(256, (1,1), activation=lambda x: x * tf.sigmoid(x)))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    # --- Classification Head ---\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,\n",
        "                   kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4),\n",
        "                   activity_regularizer=l1_l2(l1=1e-6, l2=1e-5)))\n",
        "    model.add(Activation(lambda x: x * tf.math.tanh(tf.math.softplus(x))))  # Mish\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Output with label smoothing\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Lambda(lambda x: tf.clip_by_value(tf.nn.softmax(x), 1e-7, 1.-1e-7)))\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = AdamW(learning_rate=3e-4, weight_decay=1e-5)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy', F1Score()]\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfBlHezFlIdd"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    Plot training & validation accuracy and loss\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Accuracy\n",
        "    ax1.plot(history.history['accuracy'])\n",
        "    ax1.plot(history.history['val_accuracy'])\n",
        "    ax1.set_title('Model Accuracy')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "    # Loss\n",
        "    ax2.plot(history.history['loss'])\n",
        "    ax2.plot(history.history['val_loss'])\n",
        "    ax2.set_title('Model Loss')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nY0puPVlNKD"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('confusion_matrix.png')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F4ovbcLlPvO",
        "outputId": "1f5523e3-929e-4890-a958-db2d698dcc7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 GPU(s). GPU acceleration enabled.\n",
            "Loading preprocessed data...\n",
            "['Cavity', 'Fillings', 'Impacted Tooth', 'Implant', 'Normal']\n"
          ]
        }
      ],
      "source": [
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Directory containing preprocessed data\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/dental-classification/augmented_data\"\n",
        "\n",
        "# Configure hardware acceleration\n",
        "use_gpu = configure_gpu()\n",
        "\n",
        "# Load data\n",
        "print(\"Loading preprocessed data...\")\n",
        "X_train, y_train, X_valid, y_valid, X_test, y_test, class_names = load_data(data_dir)\n",
        "# Get original sizes\n",
        "n_train = len(X_train)\n",
        "n_test = len(X_test)\n",
        "n_valid = len(X_valid)\n",
        "\n",
        "# Combine all data\n",
        "X_all = np.concatenate([X_train, X_test, X_valid], axis=0)\n",
        "y_all = np.concatenate([y_train, y_test, y_valid], axis=0)\n",
        "\n",
        "# Shuffle data\n",
        "assert len(X_all) == len(y_all)\n",
        "perm = np.random.permutation(len(X_all))\n",
        "X_all = X_all[perm]\n",
        "y_all = y_all[perm]\n",
        "\n",
        "# Split back using original sizes\n",
        "X_train= X_all[:n_train]\n",
        "y_train= y_all[:n_train]\n",
        "X_test= X_all[n_train:n_train + n_test]\n",
        "y_test= y_all[n_train:n_train + n_test]\n",
        "X_valid= X_all[n_train + n_test:]\n",
        "y_valid= y_all[n_train + n_test:]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the shuffled datasets\n",
        "np.save(\"/content/drive/MyDrive/Colab Notebooks/dental-classification/augmented_data/X_train_augmented.npy\", X_train)\n",
        "np.save(\"/content/drive/MyDrive/Colab Notebooks/dental-classification/augmented_data/y_train_augmented.npy\", y_train)\n",
        "np.save(\"/content/drive/MyDrive/Colab Notebooks/dental-classification/augmented_data/X_test.npy\", X_test)\n",
        "np.save(\"/content/drive/MyDrive/Colab Notebooks/dental-classification/augmented_data/y_test.npy\", y_test)\n",
        "np.save(\"/content/drive/MyDrive/Colab Notebooks/dental-classification/augmented_data/X_valid.npy\", X_valid)\n",
        "np.save(\"/content/drive/MyDrive/Colab Notebooks/dental-classification/augmented_data/y_valid.npy\", y_valid)"
      ],
      "metadata": {
        "id": "k-VG4FenLVDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print dataset information\n",
        "print(f\"Training set: {X_train.shape[0]} images\")\n",
        "print(f\"Validation set: {X_valid.shape[0]} images\")\n",
        "print(f\"Test set: {X_test.shape[0]} images\")\n",
        "print(f\"Number of classes: {len(class_names)}\")\n",
        "\n",
        "\n",
        "# Input shape and number of classes\n",
        "input_shape = X_train.shape[1:]  # (64, 64, 1)\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Create model\n",
        "model = create_enhanced_model(input_shape, num_classes) # Recreate your model architecture\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    #EarlyStopping(patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_dental_model.keras', save_best_only=True),\n",
        "    ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6)\n",
        "]\n",
        "\n",
        "# Batch size optimization for GPU\n",
        "batch_size = 64 if use_gpu else 32\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "# 1. Compute balanced class weights\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "#force model to build\n",
        "history = model.fit(\n",
        "    X_train,y_train,\n",
        "    epochs=1,\n",
        "    batch_size=batch_size,\n",
        "    class_weight=class_weight_dict,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "# Then load weights\n",
        "model.load_weights('/content/drive/MyDrive/Colab Notebooks/dental-classification/best_dental_model.keras')\n",
        "\n",
        "# Train the model with appropriate batch size\n",
        "print(\"\\nTraining model...\")\n",
        "history = model.fit(\n",
        "    X_train,y_train,\n",
        "    epochs=5,\n",
        "    batch_size=batch_size,\n",
        "    class_weight=class_weight_dict,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "# Plot training history\n",
        "plot_training_history(history)\n",
        "\n",
        "\n",
        "\n",
        "# Save model\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/dental-classification/dental_xray_classifier.keras')\n",
        "print(\"\\nModel saved as 'dental_xray_classifier.keras'\")"
      ],
      "metadata": {
        "id": "T1uFzWld87dD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f142aae-eb7b-4958-f9a4-629a9c3e3deb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: 57116 images\n",
            "Validation set: 2812 images\n",
            "Test set: 1649 images\n",
            "Number of classes: 5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/lambda_layer.py:65: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ self_attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ se_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SEBlock</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ self_attention (\u001b[38;5;33mSelfAttention\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m41,088\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m82,048\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ se_block (\u001b[38;5;33mSEBlock\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m33,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m1,285\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">242,949</span> (949.02 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m242,949\u001b[0m (949.02 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">242,501</span> (947.27 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m242,501\u001b[0m (947.27 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 445ms/step - accuracy: 0.7221 - f1_score: 0.9754 - loss: 0.7463 - val_accuracy: 0.8606 - val_f1_score: 0.9874 - val_loss: 0.4376 - learning_rate: 3.0000e-04\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/activations/__init__.py:76: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:     model.add(Activation(lambda x: x * tf.sigmoid(x)))  # Swish\n",
            "\n",
            "  fn_config = serialization_lib.serialize_keras_object(activation)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/activations/__init__.py:76: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:     model.add(Activation(lambda x: x * tf.sigmoid(x)))\n",
            "\n",
            "  fn_config = serialization_lib.serialize_keras_object(activation)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/activations/__init__.py:76: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:     model.add(Conv2D(256, (1,1), activation=lambda x: x * tf.sigmoid(x)))\n",
            "\n",
            "  fn_config = serialization_lib.serialize_keras_object(activation)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/activations/__init__.py:76: UserWarning: The object being serialized includes a `lambda`. This is unsafe. In order to reload the object, you will have to pass `safe_mode=False` to the loading function. Please avoid using `lambda` in the future, and use named Python functions instead. This is the `lambda` being serialized:     model.add(Activation(lambda x: x * tf.math.tanh(tf.math.softplus(x))))  # Mish\n",
            "\n",
            "  fn_config = serialization_lib.serialize_keras_object(activation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model...\n",
            "Epoch 1/5\n",
            "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 424ms/step - accuracy: 0.9502 - f1_score: 0.9936 - loss: 0.1398 - val_accuracy: 0.9477 - val_f1_score: 0.9918 - val_loss: 0.1530 - learning_rate: 1.5000e-04\n",
            "Epoch 2/5\n",
            "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 423ms/step - accuracy: 0.9516 - f1_score: 0.9937 - loss: 0.1375 - val_accuracy: 0.9474 - val_f1_score: 0.9916 - val_loss: 0.1529 - learning_rate: 1.5000e-04\n",
            "Epoch 3/5\n",
            "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 423ms/step - accuracy: 0.9515 - f1_score: 0.9937 - loss: 0.1341 - val_accuracy: 0.9438 - val_f1_score: 0.9907 - val_loss: 0.1653 - learning_rate: 1.5000e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 419ms/step - accuracy: 0.9516 - f1_score: 0.9937 - loss: 0.1327 - val_accuracy: 0.9488 - val_f1_score: 0.9920 - val_loss: 0.1471 - learning_rate: 1.5000e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m893/893\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 424ms/step - accuracy: 0.9535 - f1_score: 0.9939 - loss: 0.1293 - val_accuracy: 0.9477 - val_f1_score: 0.9911 - val_loss: 0.1509 - learning_rate: 1.5000e-04\n",
            "\n",
            "Model saved as 'dental_xray_classifier.keras'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "test_metrics = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_metrics[1]:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, class_names)"
      ],
      "metadata": {
        "id": "4xaA1AXW9Ji9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c30a3a-bdb0-41c0-fcd0-a545c2c676c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating on test set...\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.9618 - f1_score: 0.9951 - loss: 0.1299\n",
            "Test accuracy: 0.9594\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step\n",
            "\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "        Cavity       0.97      0.97      0.97       271\n",
            "      Fillings       0.97      0.88      0.92       301\n",
            "Impacted Tooth       0.99      0.98      0.99       263\n",
            "       Implant       0.97      0.99      0.98       278\n",
            "        Normal       0.93      0.97      0.95       536\n",
            "\n",
            "      accuracy                           0.96      1649\n",
            "     macro avg       0.97      0.96      0.96      1649\n",
            "  weighted avg       0.96      0.96      0.96      1649\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}